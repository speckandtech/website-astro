---
title: "#36 - Nothing to Hide"
date: 2019-12-19T20:30:00+02:00
categories: event
---

## Kindly sponsored by [ACS](//www.acs.it/it/home.html)

<iframe src="//www.slideshare.net/slideshow/embed_code/key/fvPWMP6Hu8k9kE" width="100%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" allowfullscreen> </iframe>

## AI for Humans: The Future of your Digital Self

### George Punter - Co-Founder @ [Ethi](//ethi.me/){:target="\_blank"} and [TurgenSec](//turgensec.com){:target="\_blank"}

In this talk, George will demonstrate the extent and power of personal data collected by technology companies. He will explore the potential of personal data to do both good and bad, the dangers of giving up your "digital DNA", and the value these companies extract from this data.
Data rights are finally legally recognised. With the combination of GDPR & rising awareness of personal data abuse, we might eventually be able to control our data, or at least understand as much about our digital footprint as profit-driven companies do.
AI is only possible because it has data. Imagine your data being used to benefit you, instead of targeting you with gambling adverts. Imagine the potential for next-generation research to understand our society, which can only happen if we break data out from being locked in corporate databases. Data rights are just the start, now we need to use them.

<iframe src="//www.slideshare.net/slideshow/embed_code/key/qNvHk8uba25crG" width="100%" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" allowfullscreen> </iframe>

## Computational privacy: balancing privacy and utility in the digital era

### Andrea Gadotti - Researcher @ [Computational Privacy Group](//cpg.doc.ic.ac.uk/){:target="\_blank"}

Data is incredibly useful for innovation, and in particular for business, researchers and policy-makers. Ultimately, data has huge potential for social good. However, the large-scale collection and use of data raises legitimate privacy concerns, especially in light of recent scandals such as the one of Cambridge Analytica. Traditionally, the standard tool to share data while protecting privacy has been anonymization. Yet, research has shown that this practice is not resistant to a wide range of re-identification attacks. In this presentation I will show why anonymization does not work for modern behavioral datasets ("big data"). I will also discuss how researchers are exploring alternative models to enable the privacy-conscientious use of big data, and why this is a never-ending attack/defense game.

<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTO8D2x9KKvGISRw0yDh5BqKSaJ6nPdjqoNbxH4NAqyXJZuG0LDEdIUObNz3wfngWbsGPLog4XgPZ42/embed?start=false&loop=false&delayms=15000" frameborder="0" width="100%" height="485" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

## Weren't you there?

### or maybe you just want to relive this wonderful night

<section class="fb-links">

#### Check the video!

<iframe width="560" height="315" src="https://www.youtube.com/embed/wt23esnkZ3A?start=645" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
#### and take a look at the <a id="fb_photo_album" class="btn-facebook" target="_blank" href="//bit.ly/ST36p">pictures &#128247;</a>
</section>
